{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "anticipated-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'red_data' # reduced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "robust-cooperative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC name:  BTODstDX_MC\n",
      "data name:  BTODstDX_reduced\n",
      "----\n",
      "m_Kpipi\n",
      "low:  1820\n",
      "high:  1950\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from definition import (\n",
    "    data_names,\n",
    "    limits_m_Kpipi,\n",
    "    columns\n",
    ")\n",
    "\n",
    "MC_name   = data_names['MC']\n",
    "data_name = data_names[data_type]\n",
    "\n",
    "low_m_Kpipi = limits_m_Kpipi[data_type]['low']\n",
    "high_m_Kpipi = limits_m_Kpipi[data_type]['high']\n",
    "\n",
    "print(\"MC name: \", MC_name)\n",
    "print(\"data name: \", data_name)\n",
    "print('----')\n",
    "print('m_Kpipi')\n",
    "print(\"low: \", low_m_Kpipi)\n",
    "print(\"high: \", high_m_Kpipi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-japan",
   "metadata": {},
   "source": [
    "The columns that need to be looked at are:\n",
    "- $q^2$: `q2_reco`\n",
    "- *isolation BDT*: `isolation_bdt`\n",
    "- $t_\\tau$: `tau_life_reco`\n",
    "- $m(D^*K\\pi\\pi)$: `m_DstKpipi`\n",
    "- The angles \n",
    "    - $\\theta_X$ ($=\\theta_D$ of the paper?): `theta_X_reco`\n",
    "    - $\\theta_L$: `theta_L_reco`\n",
    "    - $\\chi$: `chi_reco`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-allowance",
   "metadata": {},
   "source": [
    "# Reweighting MC sample of $B \\to D^{*-}\\left(D^{+} \\to K^+ \\pi^+ \\pi^+  \\right)X$ Background\n",
    "\n",
    "**INPUTS**\n",
    "- `MC`: $D^+ \\to K^+ \\pi^+ \\pi^-$\n",
    "- `data`: LHCb data, with $_s$Weights to project in the $D^+ \\to K^+ \\pi^+ \\pi^-$ contribution and project out the other contributions.\n",
    "\n",
    "**GOALS**\n",
    "1. to learn the weights to apply to MC to align MC to data for the $D^+ \\to K^+ \\pi^+ \\pi^- $ decays by looking at the MC and $_s$Weighted LHCb data (using BDTs),\n",
    "2. to apply the weights to the general MC.\n",
    "\n",
    "We hope that this will reweight the general MC sample for $B \\to D^{*-} (D^+ \\to 3\\pi X) X$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "maritime-basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/06\n"
     ]
    }
   ],
   "source": [
    "# python libraries\n",
    "import zfit\n",
    "import timeit\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "# hep_ml\n",
    "from hep_ml.reweight import GBReweighter\n",
    "\n",
    "# bd2dsttaunu\n",
    "from bd2dsttaunu.locations import loc\n",
    "\n",
    "# HEA library\n",
    "from HEA.plot import plot_hist_auto, plot_hist, save_fig, plot_divide_auto\n",
    "from HEA import load_dataframe\n",
    "from HEA.plot.tools import draw_vline\n",
    "from HEA.definition import latex_params\n",
    "from HEA.pandas_root import load_saved_root\n",
    "from HEA.pandas_root import save_root\n",
    "import HEA.BDT as bt\n",
    "from HEA.tools.serial import dump_joblib, retrieve_joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concrete-plasma",
   "metadata": {},
   "source": [
    "## Read the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "center-welcome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /data/lhcb/users/scantlebury-smead/angular_analysis/double_charm/final_ds_selection_B_DstDpX_Kpipi_truth_matched.root\n",
      "Loading /home/correiaa/bd2dsttaunu/output//root/BTODstDX_reduced/BTODstDX_reduced_with_sWeights.root\n"
     ]
    }
   ],
   "source": [
    "df = {}\n",
    "df['MC'] = load_dataframe(loc.B2DstDplusX_MC, tree_name='DecayTreeTuple/DecayTree', columns=columns+['m_Kpipi'])\n",
    "df['data'] = load_saved_root(data_name + '_with_sWeights', folder_name=data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "severe-upset",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MC'] = df['MC'].query(f'm_Kpipi > {low_m_Kpipi} and m_Kpipi < {high_m_Kpipi}')\n",
    "# df['data'] = df['data'].query(f'm_Kpipi > {low_m_Kpipi} and m_Kpipi < {high_m_Kpipi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-barcelona",
   "metadata": {},
   "source": [
    "## Theory - reweighting the MC data\n",
    "https://indico.cern.ch/event/397113/contributions/1837841/attachments/1213955/1771752/ACAT2016-reweighting.pdf\n",
    "\n",
    "Use of the `hep_ml` package: documentation [here](https://arogozhnikov.github.io/hep_ml/reweight.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-prisoner",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "#### 1D comparison cannot be used\n",
    "We could assign compute the weights in the following way:\\\n",
    "For the bin $i$: \n",
    "$$w_{i}= \\frac{\\text{#data}[i]}{\\text{#MC}[i]}$$\n",
    "\n",
    "Disadvantages:\n",
    "- Reweighting one variable might bring disagreement to others\\\n",
    "$\\Rightarrow$ we need a multi-dimensional reweighting procedure.\\\n",
    "$\\Rightarrow$ we need to compare multi-dimensional histograms!\n",
    "- We need to choose the number of bins\n",
    "\n",
    "#### Use ML (boosted reweighting)\n",
    "The procedure is automatised using a ML classifier using decision trees (e.g., gradient classifier).\\\n",
    "1. Dataset = concatenated MC and data (goal: classify MC and data events via a ML classifier)²²²\n",
    "2. Tree splits the space of variables orthogonaly to maximise the difference between MC and LHCb data in these regions. The difference is evaluated with the symmetrised $\\chi^2$ (instead of the usual *MSE*):\n",
    "$$\\chi^2 = \\sum_{\\text{bin }i} \\frac{\\left(\\text{#data}[i]-\\text{#MC}[i]\\right)^2}{\\text{#data}[i]+\\text{#MC}[i]}$$\n",
    "2. Compute weight predictions in leaves\n",
    "\n",
    "Advantages:\n",
    "- Optimal choice of region\n",
    "- Information about the efficiency of the procedure (via the ROC curve for instance)\n",
    "- The ML classifier can be used to re-weight other MC samples\n",
    "- Posssible computation of feature importances\n",
    "\n",
    "Disadvantage: slow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-cemetery",
   "metadata": {},
   "source": [
    "### `GBReweighter` in `hep_ml`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-haiti",
   "metadata": {},
   "source": [
    "We are going to use a `GBReweighter` from the `hep_ml` package. Hopefully, a description is provided by the documentation:\n",
    "\n",
    "*Gradient Boosted Reweighter - a reweighter algorithm based on ensemble of regression trees. Parameters have the same role, as in gradient boosting. Special loss function is used, trees are trained to maximize symmetrized binned chi-squared statistics.*\n",
    "\n",
    "*Training takes much more time than for bin-based versions, but GBReweighter is capable to work in high dimensions while keeping reweighting rule reliable and precise (and even smooth if many trees are used).*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inner-housing",
   "metadata": {},
   "source": [
    "## Prepare the dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-christianity",
   "metadata": {},
   "source": [
    "### Pick up the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reliable-savannah",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 available columns:\n",
      "- m_Kpipi\n",
      "- q2_reco\n",
      "- isolation_bdt\n",
      "- tau_life_reco\n",
      "- m_DstKpipi\n",
      "- theta_X_reco\n",
      "- theta_L_reco\n",
      "- chi_reco\n",
      "- costheta_X_reco\n",
      "- costheta_L_reco\n",
      "- coschi_reco\n",
      "- tau_M\n",
      "- B0_M\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(columns)} available columns:\")\n",
    "for column in columns:\n",
    "    print(\"- \" + column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "covered-degree",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 columns used for training of the GBRWeighter:\n",
      "- costheta_X_reco\n",
      "- costheta_L_reco\n",
      "- chi_reco\n",
      "- isolation_bdt\n",
      "- q2_reco\n"
     ]
    }
   ],
   "source": [
    "training_columns = [\n",
    "    'costheta_X_reco',\n",
    "    'costheta_L_reco',\n",
    "    'chi_reco',\n",
    "    'isolation_bdt',\n",
    "    'q2_reco'\n",
    "]\n",
    "\n",
    "print(f\"{len(training_columns)} columns used for training of the GBRWeighter:\")\n",
    "for training_column in training_columns:\n",
    "    print(\"- \" + training_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subjective-richardson",
   "metadata": {},
   "source": [
    "We are also going to try to add $m(D^*3\\pi)$ to the trained variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "automatic-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns_2 = training_columns + ['B0_M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "practical-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_columns_dict = {\n",
    "    \"basic\": training_columns, \n",
    "    \"with_B0_M\": training_columns_2,   \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-translator",
   "metadata": {},
   "source": [
    "### Get the dataframes with only the training variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "starting-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = {\n",
    "#     'MC': df['MC'][training_columns],\n",
    "#     'data': df['data'][training_columns]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "consolidated-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['MC']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-egypt",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dress-excuse",
   "metadata": {},
   "source": [
    "### hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "smaller-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams ={\n",
    "#     'n_estimators': 100,\n",
    "#     'learning_rate': 0.1,\n",
    "#     'max_depth': 3,\n",
    "#     'min_samples_leaf': 200\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-bikini",
   "metadata": {},
   "source": [
    "### Reweigher classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "circular-necklace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reweighter = GBReweighter(**hyperparams)\n",
    "\n",
    "# reweighter = reweighter.fit(\n",
    "#     original=df_train['MC'], \n",
    "#     target=df_train['data'], \n",
    "#     target_weight=df['data']['sWeight']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "figured-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC_weights = reweighter.predict_weights(df_train['MC'])\n",
    "# MC_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-moral",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "double-ordinance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df['MC']['weight'] = MC_weights\n",
    "# save_root(df['MC'], MC_name + '_B0_M_with_weights', 'DecayTree', folder_name=MC_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-veteran",
   "metadata": {},
   "source": [
    "### LOOP different variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nonprofit-garlic",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams ={\n",
    "#     'n_estimators': 200,\n",
    "    'n_estimators': 30, # defaut:30\n",
    "    'learning_rate': 0.2, # defaut:0.2\n",
    "    'max_depth': 3, # defaut\n",
    "    'min_samples_leaf': 200 # defaut\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dimensional-halloween",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reweighting of: basic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/correiaa/miniconda/envs/bd2dsttaunu_env/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root file saved in /home/correiaa/bd2dsttaunu/output/root/BTODstDX_MC/BTODstDX_MC_basic_with_weights.root\n",
      "Joblib file saved in /home/correiaa/bd2dsttaunu/output/joblib/BTODstDX_MC/BTODstDX_MC_basic_with_weights.joblib\n",
      "Reweighting of: with_B0_M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/correiaa/miniconda/envs/bd2dsttaunu_env/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root file saved in /home/correiaa/bd2dsttaunu/output/root/BTODstDX_MC/BTODstDX_MC_with_B0_M_with_weights.root\n",
      "Joblib file saved in /home/correiaa/bd2dsttaunu/output/joblib/BTODstDX_MC/BTODstDX_MC_with_B0_M_with_weights.joblib\n"
     ]
    }
   ],
   "source": [
    "reweighter=[]\n",
    "for name_training, training_columns in training_columns_dict.items():\n",
    "    print(f\"Reweighting of: {name_training}\")\n",
    "    \n",
    "    df_train = {\n",
    "        'MC': df['MC'][training_columns],\n",
    "        'data': df['data'][training_columns]\n",
    "    }\n",
    "    \n",
    "    reweighter = GBReweighter(**hyperparams)\n",
    "    reweighter.fit(original=df_train['MC'], target=df_train['data'], \n",
    "                   target_weight=df['data']['sWeight'])\n",
    "    \n",
    "    df_train['MC']['weight'] = reweighter.predict_weights(df_train['MC'])\n",
    "    \n",
    "    MC_file_name = MC_name + f'_{name_training}_with_weights'\n",
    "    \n",
    "    save_root(df_train['MC'], MC_file_name, 'DecayTree', folder_name=MC_name)\n",
    "    dump_joblib(reweighter, MC_file_name, folder_name=MC_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-polyester",
   "metadata": {},
   "source": [
    "Check that the jobfile have been correctly saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "differential-ebony",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_reweighter = retrieve_joblib(MC_file_name, folder_name=MC_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "widespread-passport",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(reweighter.predict_weights(df_train['MC'].drop('weight', 1))==retrieved_reweighter.predict_weights(df_train['MC'].drop('weight', 1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd2dsttaunu_env",
   "language": "python",
   "name": "bd2dsttaunu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
